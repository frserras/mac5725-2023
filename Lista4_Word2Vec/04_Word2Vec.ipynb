{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zljehcW10P5q"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/alan-barzilay/NLPortugues/master/imagens/logo_nlportugues.png\"   width=\"150\" align=\"right\">\n",
        "\n",
        "# Lista 4 - Word2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bUareHn6UqM"
      },
      "source": [
        "______________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tw8FPTMX0P5s"
      },
      "source": [
        "Nessa lista nós exploraremos o espaço vetorial gerado pelo algoritmo Word2Vec e algumas de suas propriedades mais interessantes. Veremos como palavras similares se organizam nesse espaço e as relações de palavras com seus sinônimos e antônimos. Também veremos algumas analogias interessantes que o algoritmo é capaz de fazer ao capturar um pouco do nosso uso da língua portuguesa.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vR52KVnq0P5t"
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KUL7X3F0P5u"
      },
      "source": [
        "# Carregando dados\n",
        "\n",
        "\n",
        "Para esta lista nós utilizaremos vetores de palavras, também conhecidos como *embeddings*, para lingua portuguesa fornecidos pelo [NILC](http://www.nilc.icmc.usp.br/nilc/index.php). Nós utilizaremos o embedding de 50 dimensões treinado com o algoritmo Word2Vec (Continous Bag of Words) que pode ser encontrado [aqui](http://www.nilc.icmc.usp.br/embeddings) sob a licensa [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/). Para evitar problemas de mémoria utilizaremos apenas as 200 mil palavras mais comum."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEwqxBvD0Rga"
      },
      "outputs": [],
      "source": [
        "!curl  https://raw.githubusercontent.com/alan-barzilay/NLPortugues/master/Semana%2004/data/word2vec_200k.txt --output 'word2vec_200k.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bwajr5sQ0P5v"
      },
      "outputs": [],
      "source": [
        "# Carrega word2vec\n",
        "model = KeyedVectors.load_word2vec_format(\"word2vec_200k.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2JYtS1k0P5v"
      },
      "source": [
        "# Similaridade e Distância Cosseno\n",
        "\n",
        "Como comentamos em sala de aula, podemos considerar as palavras como pontos num espaço n-dimensional e podemos examinar a proximidade delas através da similaridade cosseno:\n",
        "$$s = \\frac{u \\cdot v}{||u|| ||v||}, \\textrm{ onde } s \\in [-1, 1] $$\n",
        "\n",
        "\n",
        "## <font color='blue'>Questão 1 </font>\n",
        "Palavras [polissemicas](https://pt.wikipedia.org/wiki/Polissemia) e [homônimas](https://pt.wikipedia.org/wiki/Hom%C3%B3nimo) são palavras que possuem mais de um significado.\n",
        "\n",
        "\n",
        "Utilizando a função `model.most_similar()`, encontre uma palavra que possua múltiplos significados e que na sua lista de 10 palavras mais similares existam palavras relacionadas a mais de um dos seus significados, lembre-se de consultar sua [documentação](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.FastTextKeyedVectors.most_similar).\n",
        "\n",
        "Por exemplo, a palavra \"manga\" possui na sua lista de 10 palavras mais similares as palavras \"gola\" e \"lapela\" (que estão relacionadas ao significado de manga de uma camiseta) e a palavra \"maçã\" (que está relacionada ao significado da fruta manga).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbvAUIa30P5w"
      },
      "outputs": [],
      "source": [
        "# Seu código aqui"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLh82IfO0P5x"
      },
      "source": [
        "\n",
        "**<font color='red'> Sua resposta aqui </font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6YKYZ_z0P5x"
      },
      "source": [
        "# Sinônimos e Antônimos\n",
        "\n",
        "\n",
        "As vezes é mais intuitivo trabalhar com uma medida de distancia ao invés da similaridade cosseno, para isso vamos utilizar a distancia cosseno que é simplesmente 1 - Similaridade Cosseno.\n",
        "\n",
        "## <font color='blue'>Questão 2 </font>\n",
        "\n",
        "\n",
        "Usando a função [`model.distance(palavra1,palavra2)`](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.FastTextKeyedVectors.distance), encontre 3 palavras onde as palavras p1 e p2 são sinônimas e p1 e p3 são antônimas mas `distance(p1,p3)` < `distance(p1,p2)`.\n",
        "\n",
        "Proponha uma explicação do porque esse resultado contraintuitivo acontece.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeywFdKk0P5y"
      },
      "outputs": [],
      "source": [
        "# Seu código aqui"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ncOIj240P5y"
      },
      "source": [
        "\n",
        "**<font color='red'> Sua resposta aqui </font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9Se982Q0P5z"
      },
      "source": [
        "# Analogias\n",
        "\n",
        "Existem algumas analogias famosas realizadas por vetores de palavras. O exemplo mais famoso é provavelmente \"man : king :: woman : x\", onde x é *queen*.\n",
        "\n",
        "Para formular analogias vamos utilizar a função `most_similar()` que busca as palavras mais similares as listas em  `positive` e mais dissimilares as listadas em  `negative`. Para mais detalhes recomendamos consultar a sua [documentação](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.FastTextKeyedVectors.most_similar).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8zujhY70P5z"
      },
      "outputs": [],
      "source": [
        "model.most_similar(positive=['mulher', 'engenheiro'], negative=['homem'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJnuDjo-0P5z"
      },
      "source": [
        "## <font color='blue'>Questão 3 </font>\n",
        "Encontre analogias que funcionam, ou seja, que a palavra esperada está no topo da lista.\n",
        "\n",
        "Descreva sua analogia na seguinte forma:\n",
        "x:y :: a:b\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXpu7g3a0P50"
      },
      "outputs": [],
      "source": [
        "# Seu código aqui"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "788u4d3A0P50"
      },
      "source": [
        "\n",
        "**<font color='red'> Sua resposta aqui </font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "su8svdBl0P50"
      },
      "source": [
        "## <font color='blue'>Questão 4 </font>\n",
        "Encontre analogias que **Não** funcionam.\n",
        "\n",
        "Descreva o resultado esperado da sua analogia na seguinte forma:\n",
        "x:y :: a:b\n",
        "\n",
        "E indique o valor errado de b encontrado\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdQ2rtyA0P51"
      },
      "outputs": [],
      "source": [
        "# Seu código aqui"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CMzT3fy0P51"
      },
      "source": [
        "\n",
        "**<font color='red'> Sua resposta aqui </font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8LYWJ1i0P51"
      },
      "source": [
        "# Viés e preconceito adquirido\n",
        "\n",
        "Como estes vetores são aprendidos a partir de documentos produzidos dentro do nosso contexto social, eles podem capturar viéses, preconceitos e desigualdades presentes na nossa sociedade.\n",
        "\n",
        "Quando esses tipos de modelos começaram a ser treinados, cientistas ficaram surpresos com o fato de que tais viéses fossem aprendidos pelos modelos, mesmo quando os dados não continham textos específicos que defendiam posições preconceituosas ou que usassem linguagem explicitamente preconceituosa. Modelos treinados com textos a priori neutros e bastante revisados, ainda apresentam tais viéses, porque usualmente os viéses observados são fruto de preconceitos estruturais que perpassam toda a produção de uma sociedade, inclusive sua emissão linguística. Esses viéses, muitas vezes, não são objetivamente detectáveis em nível de texto individual, mas se manifestam nas correlações das palavras de forma transversal à qualquer grande volume de textos.\n",
        "\n",
        "É importante estar ciente desse tipo de viés dos modelos treinados e dos seus perigos. Aplicações que utilizam esses modelos podem perpetuar e até exarcebar desigualdades sociais, retro-alimentando as estruturas que os originaram.\n",
        "\n",
        "Para um exemplo mais concreto, vide a seguinte analogia preconceituosa capturada:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53KYiqsc0P51"
      },
      "outputs": [],
      "source": [
        "model.most_similar(positive=['negro', 'rico'], negative=['pobre'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BS-sruEp0P52"
      },
      "source": [
        "Note também como diferem as palavras mais semelhantes a homem e mulher:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgtl4cgN0P53"
      },
      "outputs": [],
      "source": [
        "model.most_similar(\"homem\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bExfFYGS0P53"
      },
      "outputs": [],
      "source": [
        "model.most_similar(\"mulher\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgNf_9-P0P53"
      },
      "source": [
        "## <font color='blue'>Questão 5 </font>\n",
        "\n",
        "Utiliza a função `most_similar()` para encontrar um outro caso de viés adquirido pelos vetores e explique brevemente o tipo de viés encontrado.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuHqTKSB0P53"
      },
      "outputs": [],
      "source": [
        "# Seu código aqui"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TID_Rbk70P53"
      },
      "source": [
        "\n",
        "**<font color='red'> Sua resposta aqui </font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5ih_CvL0P53"
      },
      "source": [
        "## <font color='blue'>Questão 6 </font>\n",
        "\n",
        "Qual é a possivel origem desses vieses? Tente explicar como eles podem ter sido capturados pelos vetores de palavras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nm8ty0WH0P54"
      },
      "source": [
        "\n",
        "**<font color='red'> Sua resposta aqui </font>**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv_tutorial",
      "language": "python",
      "name": ".venv_tutorial"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
